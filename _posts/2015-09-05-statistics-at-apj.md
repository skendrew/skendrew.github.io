---
layout: post
title: Statistics at ApJ
date: 2015-09-05
tags: publishing, statistics, journals
published: true
---

I think it's fair to say that the average astronomer's knowledge of statistics falls short of what's required for the big data-based research many of us are increasingly creeping into. Some of us take action and sign up for one of the excellent [statistics-focused meetings or summer schools](https://asaip.psu.edu/meetings) that have sprung up in recent years: the 12-step Rehab Programme for the Statistically Challenged Astronomer, seeking help after Hitting Rock Bottom having found their work disproven by 5 lines of Python code from the eager hands of the new summer intern who daily chooses her breakfast cereal via Markov Chain Monte Carlo. The rest of us just soldier on, silently praying that our executioner will be kind, and not in a position to decide on our next promotion.

I currently have a statistics-heavy paper going through peer review - a long overdue follow-up to my [2012 paper](http://adslabs.org/adsabs/abs/2012ApJ...755...71K/) examining correlations between the locations of bubbles in the interstellar medium of the Milky Way Galaxy (as identified by our [Milky Way Project](http://www.milkywayproject.org) volunteers) and other markers of high mass star formation. In the new paper, I examine the distribution and physical properties of cold dust clumps near to and away from those bubbles, using sub-millimeter data from the [ATLASGAL](http://www3.mpifr-bonn.mpg.de/div/atlasgal/) survey. 

About a week after submitting the paper to ApJ I received a first round of comments, not from the standard anonymous referee, but passed on from the journal's Statistics Editor. Whilst it means I now have two sets of comments to address, and I will probably grumble about that at a later time, the specific feedback on the statistical methods I've used is more in-depth and helpful than I've had for other papers. Apparently this is a relatively new practice at the journal, and based on this recent experience (bearing in mind the danger of extrapolating from one datapoint), one that I wholeheartedly support. There are too many papers in the literature that use overly simplistic, inappropriate or inadequate statistical methods - and yes, I'm sure that includes some of my own efforts.  

It's nice to see a journal play an active role in improving the quality of the science presented in the literature, and it's made me a little more confident that Kendrew et al 2015b will not be the cause of my statistical downfall.
